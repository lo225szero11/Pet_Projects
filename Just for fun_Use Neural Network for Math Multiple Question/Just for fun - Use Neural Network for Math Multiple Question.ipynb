{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just for fun - Use Neural Network for Math Multiple Question\n",
    "\n",
    "Arthur: Leon Lai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic question that every programmer might solve for coding learning in the beginning below:\n",
    "\n",
    "In the numbers 1 ~ 100,\n",
    "* if it's the multiple of 3 & 5, print '3'\n",
    "* if it's only the multiple of 5, print '2'\n",
    "* if it's only the multiple of 3, print '1'\n",
    "* if it's not all of above, print '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0\n",
      "2: 0\n",
      "3: 1\n",
      "4: 0\n",
      "5: 2\n",
      "6: 1\n",
      "7: 0\n",
      "8: 0\n",
      "9: 1\n",
      "10: 2\n",
      "11: 0\n",
      "12: 1\n",
      "13: 0\n",
      "14: 0\n",
      "15: 3\n",
      "16: 0\n",
      "17: 0\n",
      "18: 1\n",
      "19: 0\n",
      "20: 2\n",
      "21: 1\n",
      "22: 0\n",
      "23: 0\n",
      "24: 1\n",
      "25: 2\n",
      "26: 0\n",
      "27: 1\n",
      "28: 0\n",
      "29: 0\n",
      "30: 3\n",
      "31: 0\n",
      "32: 0\n",
      "33: 1\n",
      "34: 0\n",
      "35: 2\n",
      "36: 1\n",
      "37: 0\n",
      "38: 0\n",
      "39: 1\n",
      "40: 2\n",
      "41: 0\n",
      "42: 1\n",
      "43: 0\n",
      "44: 0\n",
      "45: 3\n",
      "46: 0\n",
      "47: 0\n",
      "48: 1\n",
      "49: 0\n",
      "50: 2\n",
      "51: 1\n",
      "52: 0\n",
      "53: 0\n",
      "54: 1\n",
      "55: 2\n",
      "56: 0\n",
      "57: 1\n",
      "58: 0\n",
      "59: 0\n",
      "60: 3\n",
      "61: 0\n",
      "62: 0\n",
      "63: 1\n",
      "64: 0\n",
      "65: 2\n",
      "66: 1\n",
      "67: 0\n",
      "68: 0\n",
      "69: 1\n",
      "70: 2\n",
      "71: 0\n",
      "72: 1\n",
      "73: 0\n",
      "74: 0\n",
      "75: 3\n",
      "76: 0\n",
      "77: 0\n",
      "78: 1\n",
      "79: 0\n",
      "80: 2\n",
      "81: 1\n",
      "82: 0\n",
      "83: 0\n",
      "84: 1\n",
      "85: 2\n",
      "86: 0\n",
      "87: 1\n",
      "88: 0\n",
      "89: 0\n",
      "90: 3\n",
      "91: 0\n",
      "92: 0\n",
      "93: 1\n",
      "94: 0\n",
      "95: 2\n",
      "96: 1\n",
      "97: 0\n",
      "98: 0\n",
      "99: 1\n",
      "100: 2\n"
     ]
    }
   ],
   "source": [
    "for num in range(1,101):\n",
    "    if num % 3 == 0 and num % 5 == 0:\n",
    "        print(num,': ',3,sep='')\n",
    "    elif num % 5 == 0:\n",
    "        print(num,': ',2,sep='')\n",
    "    elif num % 3 == 0:\n",
    "        print(num,': ',1,sep='')\n",
    "    else:\n",
    "        print(num,': ',0,sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Just for fun, maybe we can use Neural Network to make machine learn to solve it!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan to make a dataset with 1 ~ 1000 \n",
    "* 1 ~ 100 is the test set\n",
    "* 101 ~ 1000 is the train set\n",
    "\n",
    "The input feature is the number transformed to binary array.\n",
    "\n",
    "For example,\n",
    "\n",
    "* 1 : [0,0,0,0,0,0,0,0,0,1]\n",
    "* 100 : [0,0,0,1,1,0,0,1,0,0]\n",
    "\n",
    "The output is the array of 4 digits:\n",
    "\n",
    "* the multiple of 3 & 5: [0,0,0,1]\n",
    "* only the multiple of 5: [0,0,1,0]\n",
    "* only the multiple of 3: [0,1,0,0]\n",
    "* none of above: [1,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(sample_num):\n",
    "    if sample_num > 1000:\n",
    "        print('out of number')\n",
    "        return \n",
    "    x = np.zeros((sample_num+1,10))\n",
    "    y = np.zeros((sample_num+1,4))\n",
    "    for num in range(sample_num+1):\n",
    "        temp = num\n",
    "        for digit_x in range(9,-1,-1):\n",
    "            x[num,9-digit_x] = temp // (2**digit_x)\n",
    "            temp = temp % (2**digit_x)\n",
    "        if num % 3 == 0 and num % 5 == 0:\n",
    "            y[num,3] = 1\n",
    "        elif num % 5 == 0:\n",
    "            y[num,2] = 1\n",
    "        elif num % 3 == 0:\n",
    "            y[num,1] = 1\n",
    "        else:\n",
    "            y[num,0] = 1\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = create_data(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x[1:101,:] # 1 ~ 100 \n",
    "Y_test = y[1:101,:]\n",
    "X_train = x[101:,:] # 101 ~ 1000\n",
    "Y_train = y[101:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 1., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 1., 0., 1., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 1., 1., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 1., 1., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 0., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 1., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 1., 0., 1., 1.],\n",
       "       [0., 0., 0., 1., 0., 1., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 1., 1., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 1., 1., 1., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 1., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 1., 0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Neural Network\n",
    "\n",
    "Use Keras kit to build a simple neural network (one hidden layer). \n",
    "\n",
    "The optimizer is 'Adam'. (batch_size=20,epochs=150)\n",
    "\n",
    "* Input: 10 units\n",
    "* hidden layer: 1000 units (Activation: Rectified Linear Unit)\n",
    "* output: 4 units (Activation: Softmax for multi-classfication)\n",
    "\n",
    "Also use a monitor to control the learning rate if the accuracy doesn't decline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Leon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(input_dim=10, units=1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=4, activation = \"softmax\"))\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Leon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "900/900 [==============================] - 1s 662us/step - loss: 1.1939 - acc: 0.5133\n",
      "Epoch 2/150\n",
      "900/900 [==============================] - 0s 75us/step - loss: 1.1509 - acc: 0.5333\n",
      "Epoch 3/150\n",
      "900/900 [==============================] - 0s 96us/step - loss: 1.1462 - acc: 0.5333\n",
      "Epoch 4/150\n",
      "900/900 [==============================] - 0s 90us/step - loss: 1.1391 - acc: 0.5333\n",
      "Epoch 5/150\n",
      "900/900 [==============================] - 0s 102us/step - loss: 1.1299 - acc: 0.5333\n",
      "Epoch 6/150\n",
      "900/900 [==============================] - 0s 111us/step - loss: 1.1206 - acc: 0.5333\n",
      "Epoch 7/150\n",
      "900/900 [==============================] - 0s 102us/step - loss: 1.1063 - acc: 0.5333\n",
      "Epoch 8/150\n",
      "900/900 [==============================] - 0s 97us/step - loss: 1.0910 - acc: 0.5333\n",
      "Epoch 9/150\n",
      "900/900 [==============================] - 0s 124us/step - loss: 1.0735 - acc: 0.5356\n",
      "Epoch 10/150\n",
      "900/900 [==============================] - 0s 95us/step - loss: 1.0553 - acc: 0.5367\n",
      "Epoch 11/150\n",
      "900/900 [==============================] - 0s 101us/step - loss: 1.0366 - acc: 0.5411\n",
      "Epoch 12/150\n",
      "900/900 [==============================] - 0s 93us/step - loss: 1.0177 - acc: 0.5411\n",
      "Epoch 13/150\n",
      "900/900 [==============================] - 0s 86us/step - loss: 0.9915 - acc: 0.5556\n",
      "Epoch 14/150\n",
      "900/900 [==============================] - 0s 93us/step - loss: 0.9705 - acc: 0.5633\n",
      "Epoch 15/150\n",
      "900/900 [==============================] - 0s 82us/step - loss: 0.9464 - acc: 0.5700\n",
      "Epoch 16/150\n",
      "900/900 [==============================] - 0s 115us/step - loss: 0.9207 - acc: 0.5844\n",
      "Epoch 17/150\n",
      "900/900 [==============================] - 0s 96us/step - loss: 0.8971 - acc: 0.5911\n",
      "Epoch 18/150\n",
      "900/900 [==============================] - 0s 85us/step - loss: 0.8642 - acc: 0.6011\n",
      "Epoch 19/150\n",
      "900/900 [==============================] - 0s 90us/step - loss: 0.8413 - acc: 0.6444\n",
      "Epoch 20/150\n",
      "900/900 [==============================] - 0s 98us/step - loss: 0.8103 - acc: 0.6422\n",
      "Epoch 21/150\n",
      "900/900 [==============================] - 0s 96us/step - loss: 0.7801 - acc: 0.6756\n",
      "Epoch 22/150\n",
      "900/900 [==============================] - 0s 97us/step - loss: 0.7573 - acc: 0.6844\n",
      "Epoch 23/150\n",
      "900/900 [==============================] - 0s 107us/step - loss: 0.7275 - acc: 0.7211\n",
      "Epoch 24/150\n",
      "900/900 [==============================] - 0s 103us/step - loss: 0.6926 - acc: 0.7611\n",
      "Epoch 25/150\n",
      "900/900 [==============================] - 0s 94us/step - loss: 0.6686 - acc: 0.7656\n",
      "Epoch 26/150\n",
      "900/900 [==============================] - 0s 112us/step - loss: 0.6450 - acc: 0.7833\n",
      "Epoch 27/150\n",
      "900/900 [==============================] - 0s 95us/step - loss: 0.6112 - acc: 0.8144\n",
      "Epoch 28/150\n",
      "900/900 [==============================] - 0s 109us/step - loss: 0.5903 - acc: 0.8300\n",
      "Epoch 29/150\n",
      "900/900 [==============================] - 0s 96us/step - loss: 0.5589 - acc: 0.8533\n",
      "Epoch 30/150\n",
      "900/900 [==============================] - 0s 92us/step - loss: 0.5400 - acc: 0.8711\n",
      "Epoch 31/150\n",
      "900/900 [==============================] - 0s 108us/step - loss: 0.5097 - acc: 0.9033\n",
      "Epoch 32/150\n",
      "900/900 [==============================] - 0s 82us/step - loss: 0.4953 - acc: 0.8933\n",
      "Epoch 33/150\n",
      "900/900 [==============================] - 0s 108us/step - loss: 0.4647 - acc: 0.9256\n",
      "Epoch 34/150\n",
      "900/900 [==============================] - 0s 90us/step - loss: 0.4417 - acc: 0.9344\n",
      "Epoch 35/150\n",
      "900/900 [==============================] - 0s 93us/step - loss: 0.4223 - acc: 0.9378\n",
      "Epoch 36/150\n",
      "900/900 [==============================] - 0s 119us/step - loss: 0.3937 - acc: 0.9611\n",
      "Epoch 37/150\n",
      "900/900 [==============================] - 0s 91us/step - loss: 0.3795 - acc: 0.9511\n",
      "Epoch 38/150\n",
      "900/900 [==============================] - 0s 101us/step - loss: 0.3561 - acc: 0.9689\n",
      "Epoch 39/150\n",
      "900/900 [==============================] - 0s 101us/step - loss: 0.3420 - acc: 0.9678\n",
      "Epoch 40/150\n",
      "900/900 [==============================] - 0s 101us/step - loss: 0.3301 - acc: 0.9656\n",
      "Epoch 41/150\n",
      "900/900 [==============================] - 0s 130us/step - loss: 0.3116 - acc: 0.9711\n",
      "Epoch 42/150\n",
      "900/900 [==============================] - 0s 101us/step - loss: 0.2941 - acc: 0.9789\n",
      "Epoch 43/150\n",
      "900/900 [==============================] - 0s 107us/step - loss: 0.2778 - acc: 0.9811\n",
      "Epoch 44/150\n",
      "900/900 [==============================] - 0s 86us/step - loss: 0.2812 - acc: 0.9733\n",
      "Epoch 45/150\n",
      "900/900 [==============================] - 0s 103us/step - loss: 0.2587 - acc: 0.9833\n",
      "Epoch 46/150\n",
      "900/900 [==============================] - 0s 98us/step - loss: 0.2462 - acc: 0.9811\n",
      "Epoch 47/150\n",
      "900/900 [==============================] - 0s 106us/step - loss: 0.2266 - acc: 0.9889\n",
      "Epoch 48/150\n",
      "900/900 [==============================] - 0s 107us/step - loss: 0.2174 - acc: 0.9900\n",
      "Epoch 49/150\n",
      "900/900 [==============================] - 0s 97us/step - loss: 0.2044 - acc: 0.9911\n",
      "Epoch 50/150\n",
      "900/900 [==============================] - 0s 102us/step - loss: 0.1965 - acc: 0.9922\n",
      "Epoch 51/150\n",
      "900/900 [==============================] - 0s 98us/step - loss: 0.1885 - acc: 0.9922\n",
      "Epoch 52/150\n",
      "900/900 [==============================] - 0s 93us/step - loss: 0.1791 - acc: 0.9956\n",
      "Epoch 53/150\n",
      "900/900 [==============================] - 0s 108us/step - loss: 0.1716 - acc: 0.9944\n",
      "Epoch 54/150\n",
      "900/900 [==============================] - 0s 94us/step - loss: 0.1685 - acc: 0.9900\n",
      "Epoch 55/150\n",
      "900/900 [==============================] - 0s 110us/step - loss: 0.1588 - acc: 0.9944\n",
      "Epoch 56/150\n",
      "900/900 [==============================] - 0s 107us/step - loss: 0.1492 - acc: 0.9911\n",
      "Epoch 57/150\n",
      "900/900 [==============================] - 0s 105us/step - loss: 0.1464 - acc: 0.9978\n",
      "Epoch 58/150\n",
      "900/900 [==============================] - 0s 88us/step - loss: 0.1343 - acc: 0.9978\n",
      "Epoch 59/150\n",
      "900/900 [==============================] - 0s 94us/step - loss: 0.1299 - acc: 0.9956\n",
      "Epoch 60/150\n",
      "900/900 [==============================] - 0s 104us/step - loss: 0.1257 - acc: 0.9967\n",
      "Epoch 61/150\n",
      "900/900 [==============================] - 0s 94us/step - loss: 0.1186 - acc: 0.9978\n",
      "Epoch 62/150\n",
      "900/900 [==============================] - 0s 111us/step - loss: 0.1152 - acc: 0.9978\n",
      "Epoch 63/150\n",
      "900/900 [==============================] - 0s 103us/step - loss: 0.1094 - acc: 0.9967\n",
      "Epoch 64/150\n",
      "900/900 [==============================] - 0s 88us/step - loss: 0.1044 - acc: 0.9978\n",
      "Epoch 65/150\n",
      "900/900 [==============================] - 0s 106us/step - loss: 0.1019 - acc: 0.9978\n",
      "Epoch 66/150\n",
      "900/900 [==============================] - 0s 91us/step - loss: 0.0968 - acc: 0.9978\n",
      "Epoch 67/150\n",
      "900/900 [==============================] - 0s 107us/step - loss: 0.0921 - acc: 0.9989\n",
      "Epoch 68/150\n",
      "900/900 [==============================] - 0s 105us/step - loss: 0.0891 - acc: 0.9978\n",
      "Epoch 69/150\n",
      "900/900 [==============================] - 0s 89us/step - loss: 0.0861 - acc: 0.9989\n",
      "Epoch 70/150\n",
      "900/900 [==============================] - 0s 102us/step - loss: 0.0824 - acc: 0.9989\n",
      "Epoch 71/150\n",
      "900/900 [==============================] - 0s 100us/step - loss: 0.0784 - acc: 0.9989\n",
      "Epoch 72/150\n",
      "900/900 [==============================] - 0s 103us/step - loss: 0.0757 - acc: 0.9989\n",
      "Epoch 73/150\n",
      "900/900 [==============================] - 0s 104us/step - loss: 0.0744 - acc: 0.9989\n",
      "Epoch 74/150\n",
      "900/900 [==============================] - 0s 112us/step - loss: 0.0711 - acc: 0.9989\n",
      "Epoch 75/150\n",
      "900/900 [==============================] - 0s 88us/step - loss: 0.0688 - acc: 1.0000\n",
      "Epoch 76/150\n",
      "900/900 [==============================] - 0s 88us/step - loss: 0.0657 - acc: 1.0000\n",
      "Epoch 77/150\n",
      "900/900 [==============================] - 0s 98us/step - loss: 0.0628 - acc: 1.0000\n",
      "Epoch 78/150\n",
      "900/900 [==============================] - 0s 88us/step - loss: 0.0608 - acc: 1.0000\n",
      "Epoch 79/150\n",
      "900/900 [==============================] - 0s 104us/step - loss: 0.0597 - acc: 0.9989\n",
      "Epoch 80/150\n",
      "900/900 [==============================] - 0s 89us/step - loss: 0.0578 - acc: 1.0000\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 91us/step - loss: 0.0533 - acc: 0.9989\n",
      "Epoch 82/150\n",
      "900/900 [==============================] - 0s 110us/step - loss: 0.0526 - acc: 0.9989\n",
      "Epoch 83/150\n",
      "900/900 [==============================] - 0s 96us/step - loss: 0.0502 - acc: 1.0000\n",
      "Epoch 84/150\n",
      "900/900 [==============================] - 0s 104us/step - loss: 0.0498 - acc: 0.9989\n",
      "Epoch 85/150\n",
      "900/900 [==============================] - 0s 102us/step - loss: 0.0487 - acc: 1.0000\n",
      "Epoch 86/150\n",
      "900/900 [==============================] - 0s 83us/step - loss: 0.0455 - acc: 1.0000\n",
      "Epoch 87/150\n",
      "900/900 [==============================] - 0s 92us/step - loss: 0.0439 - acc: 1.0000\n",
      "Epoch 88/150\n",
      "900/900 [==============================] - 0s 86us/step - loss: 0.0435 - acc: 1.0000\n",
      "Epoch 89/150\n",
      "900/900 [==============================] - 0s 88us/step - loss: 0.0413 - acc: 1.0000\n",
      "Epoch 90/150\n",
      "900/900 [==============================] - 0s 98us/step - loss: 0.0408 - acc: 1.0000\n",
      "Epoch 91/150\n",
      "900/900 [==============================] - 0s 85us/step - loss: 0.0388 - acc: 0.9989\n",
      "Epoch 92/150\n",
      "900/900 [==============================] - 0s 93us/step - loss: 0.0372 - acc: 1.0000\n",
      "Epoch 93/150\n",
      "900/900 [==============================] - 0s 109us/step - loss: 0.0354 - acc: 1.0000\n",
      "Epoch 94/150\n",
      "900/900 [==============================] - 0s 91us/step - loss: 0.0343 - acc: 1.0000\n",
      "Epoch 95/150\n",
      "900/900 [==============================] - 0s 97us/step - loss: 0.0335 - acc: 1.0000\n",
      "Epoch 96/150\n",
      "900/900 [==============================] - 0s 93us/step - loss: 0.0335 - acc: 1.0000\n",
      "Epoch 97/150\n",
      "900/900 [==============================] - 0s 108us/step - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 98/150\n",
      "900/900 [==============================] - 0s 105us/step - loss: 0.0306 - acc: 1.0000\n",
      "Epoch 99/150\n",
      "900/900 [==============================] - 0s 89us/step - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 100/150\n",
      "900/900 [==============================] - 0s 96us/step - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 101/150\n",
      "900/900 [==============================] - 0s 96us/step - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 102/150\n",
      "900/900 [==============================] - 0s 96us/step - loss: 0.0269 - acc: 1.0000\n",
      "Epoch 103/150\n",
      "900/900 [==============================] - 0s 116us/step - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 104/150\n",
      "900/900 [==============================] - 0s 93us/step - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 105/150\n",
      "900/900 [==============================] - 0s 99us/step - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 106/150\n",
      "900/900 [==============================] - 0s 101us/step - loss: 0.0231 - acc: 1.0000\n",
      "Epoch 107/150\n",
      "900/900 [==============================] - 0s 115us/step - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 108/150\n",
      "900/900 [==============================] - 0s 94us/step - loss: 0.0229 - acc: 1.0000\n",
      "Epoch 109/150\n",
      "900/900 [==============================] - 0s 104us/step - loss: 0.0215 - acc: 1.0000\n",
      "Epoch 110/150\n",
      "900/900 [==============================] - 0s 109us/step - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 111/150\n",
      "900/900 [==============================] - 0s 95us/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 112/150\n",
      "900/900 [==============================] - 0s 102us/step - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 113/150\n",
      "900/900 [==============================] - 0s 96us/step - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 114/150\n",
      "900/900 [==============================] - 0s 110us/step - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 115/150\n",
      "900/900 [==============================] - 0s 105us/step - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 116/150\n",
      "900/900 [==============================] - 0s 91us/step - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 117/150\n",
      "900/900 [==============================] - 0s 92us/step - loss: 0.0170 - acc: 1.0000\n",
      "Epoch 118/150\n",
      "900/900 [==============================] - 0s 82us/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 119/150\n",
      "900/900 [==============================] - 0s 88us/step - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 120/150\n",
      "900/900 [==============================] - 0s 136us/step - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 121/150\n",
      "900/900 [==============================] - 0s 100us/step - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 122/150\n",
      "900/900 [==============================] - 0s 104us/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 123/150\n",
      "900/900 [==============================] - 0s 83us/step - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 124/150\n",
      "900/900 [==============================] - 0s 96us/step - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 125/150\n",
      "900/900 [==============================] - 0s 90us/step - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 126/150\n",
      "900/900 [==============================] - 0s 94us/step - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 127/150\n",
      "900/900 [==============================] - 0s 107us/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 128/150\n",
      "900/900 [==============================] - 0s 91us/step - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 129/150\n",
      "900/900 [==============================] - 0s 107us/step - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 130/150\n",
      "900/900 [==============================] - 0s 106us/step - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 131/150\n",
      "900/900 [==============================] - 0s 85us/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 132/150\n",
      "900/900 [==============================] - 0s 104us/step - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 133/150\n",
      "900/900 [==============================] - 0s 95us/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 134/150\n",
      "900/900 [==============================] - 0s 89us/step - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 135/150\n",
      "900/900 [==============================] - 0s 100us/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 136/150\n",
      "900/900 [==============================] - 0s 95us/step - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 137/150\n",
      "900/900 [==============================] - 0s 114us/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 138/150\n",
      "900/900 [==============================] - 0s 101us/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 139/150\n",
      "900/900 [==============================] - 0s 95us/step - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 140/150\n",
      "900/900 [==============================] - 0s 99us/step - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 141/150\n",
      "900/900 [==============================] - 0s 93us/step - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 142/150\n",
      "900/900 [==============================] - 0s 95us/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 143/150\n",
      "900/900 [==============================] - 0s 104us/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 144/150\n",
      "900/900 [==============================] - 0s 98us/step - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 145/150\n",
      "900/900 [==============================] - 0s 92us/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 146/150\n",
      "900/900 [==============================] - 0s 103us/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 147/150\n",
      "900/900 [==============================] - 0s 136us/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 148/150\n",
      "900/900 [==============================] - 0s 88us/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 149/150\n",
      "900/900 [==============================] - 0s 91us/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 150/150\n",
      "900/900 [==============================] - 0s 93us/step - loss: 0.0066 - acc: 1.0000\n",
      "100/100 [==============================] - 0s 918us/step\n",
      "\n",
      "Test acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,batch_size=20,epochs=150,callbacks=[learning_rate_reduction])\n",
    "test_result = model.evaluate(X_test,Y_test,batch_size=1000)\n",
    "print('\\nTest acc:',test_result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The train accuracy and test accuracy are both 100%. Success!!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
