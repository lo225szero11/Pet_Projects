{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d4c08f48-fe23-4ddb-ac46-d97f05397514",
    "_uuid": "f2156d1dd26a1243e18512002e10872c5bd7271e"
   },
   "source": [
    "# Digit Recognizer\n",
    "Arthur: Leon Lai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network (CNN) is very powerful for image recognition!\n",
    "\n",
    "Let's get started! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "f67b9393-8ea1-4e23-b856-2ce149cfe421",
    "_execution_state": "idle",
    "_uuid": "72334cb006d02a4bcfc2a2fe622524eba824c6f8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6d2fb3e6-ab71-4974-b5a2-4af1ebdb99f4",
    "_execution_state": "idle",
    "_uuid": "86061d98eccaa02efe0dab0fa3884e71fcf4c310"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "5e51d00e-62fd-4141-bf73-50ac4f2da7d0",
    "_execution_state": "idle",
    "_uuid": "84bbd5ab8d7895bd430d5ecfe2f7ddf77baa7b74"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "\n",
       "[3 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data description, each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. \n",
    "\n",
    "The feature 'label' is the number of each image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the quantity of each number in the train set first!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "86570a36-5c20-460a-9dfd-2070548532a7",
    "_execution_state": "idle",
    "_uuid": "1213b979d5ed3e0d13824d17d694c79d2ece92fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train['label']\n",
    "X_train = train.drop('label',axis = 1) \n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5aea4062-1790-4987-b739-c4bebd79030f",
    "_uuid": "b7b1b1d36243c885e57374c8b60c5a7e10abe922"
   },
   "source": [
    "It seems that there are similar counts for 0 ~ 9 digits. Good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5b7d4b66-a140-4fcc-a889-bcef007c880a",
    "_uuid": "5d77934302869925c19128c77e247b3c8ca84d71"
   },
   "source": [
    "**We also need to check if there are missing values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "ececaa00-2ae3-4d13-b631-438df085b030",
    "_execution_state": "idle",
    "_uuid": "cdf27c27e2a5b15e6d7bfc70de7a18c08f3feb7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "92572e80-8543-4e72-8767-5c9be8381b04",
    "_execution_state": "idle",
    "_uuid": "a0089bb7ec9aec76373db475399aea24699ae989"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09d04cae-4245-4659-85dd-ef48531da295",
    "_uuid": "c0bee59691c2df0b275c78e38e7f9907d02ac038"
   },
   "source": [
    "No missing data! We can go ahead!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6812040d-80ad-43d2-a571-275f4f20067b",
    "_uuid": "2954681f25f0dcbe986e6914396cdbce61db591f"
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "159d5854-437a-4d0f-bc1e-fc3f7e43d178",
    "_uuid": "0ecf4b52510ab7957d0d4eb646c0aa1ba5986273"
   },
   "source": [
    "Perform the normalization for images to make all the data values in the range of 0 ~ 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "cdc4340b-6e24-4e12-be99-ac806098ff17",
    "_execution_state": "idle",
    "_uuid": "b5d4f8fcf2a967e2c7d57daedf95aa8c5ab7f8cb"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7413df94-bcb9-4f75-b174-c127d4445766",
    "_uuid": "a66741bf1ac597094f3a3166877008feef27c519"
   },
   "source": [
    "## Reshape the data\n",
    "\n",
    "Just reshape the data as image input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "34b6a5f7-8fd2-4387-8ef4-c9dc19584fed",
    "_execution_state": "idle",
    "_uuid": "f0a6ad80dab8e0f2c2e46165ccd9cd82dd162bc3"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use **matplotlib.pyplot.imshow()** to view the images! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(X_train[0,:,:,0]); #change the first dimension (sample index) for viewing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bdb422e2-bdec-444f-97a5-283a1e54bf2c",
    "_uuid": "39b7a31e843bac6b705461bcce89da216b91799e"
   },
   "source": [
    "## Encode the label\n",
    "\n",
    "It's the multi-classfication case. The target feature 'label' will be transformed into one-hot encoding vector.\n",
    "\n",
    "For example, 1 -> [0,1,0,0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "4b7f3e78-44dc-4561-b1f0-9429ee024cf4",
    "_execution_state": "idle",
    "_uuid": "cabefd1478d5c1bdfe57fd6a34395340916a854c"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "32152fc3-a570-4d64-8a7d-6c689a4acd33",
    "_uuid": "d8abbbf31483b94e1b29d07c4c8253d1311648a7"
   },
   "source": [
    "## Split train set for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "dcd25ebb-d845-4d32-9867-082e352b1396",
    "_execution_state": "idle",
    "_uuid": "b779ac76d8317647db92d5a88b4098d212d72884"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d5265777-aeb3-449d-b171-d88cad74c0a4",
    "_uuid": "5fa18b37a9acd9e098bac1d12264b0dd4310fdd3"
   },
   "source": [
    "## Build the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we build is structured like a small VGG (one of classic CNN models).\n",
    "\n",
    "Do the batch normalization to speed up the optimization.\n",
    "\n",
    "Use dropout to reduce the over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "1e0f3f88-2ad7-459e-8e02-aecc5f3511ae",
    "_execution_state": "idle",
    "_uuid": "f7991ef6871a26f9fa57acdcd460a69bab53e804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Leon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Leon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                 input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Adam as optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "a4c55409-6a65-400a-b5e8-a1dc535429c0",
    "_execution_state": "idle",
    "_uuid": "420c704367b397b8255fefe9d882b35ac8929b95"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "0bd89b79-1a74-40da-af9a-7a76a8b96ff2",
    "_execution_state": "idle",
    "_uuid": "b4c0288622227a3cd05479aa765e324dbb852f34"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer= optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also use a monitor to control the learning rate if the accuracy doesn't decline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "b5987a18-6bbe-42a2-9d31-333ebc4f7af1",
    "_execution_state": "idle",
    "_uuid": "c4a5b4e462ec5362c47eef4fcc7956fd4e203307"
   },
   "outputs": [],
   "source": [
    "monitor = ReduceLROnPlateau(monitor='val_acc', \n",
    "                            patience=2, \n",
    "                            verbose=1, \n",
    "                            factor=0.5, \n",
    "                            min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "241a0f4f-13f5-4b13-be1e-4e3e4a714c06",
    "_uuid": "f24df64b223e0177c94025b6767ab19b722c5386"
   },
   "source": [
    "## Data augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e2d41e30-0724-40fb-a901-750e514ba9f9",
    "_uuid": "9e498b91419439f0fa791e595f202d9a0d56ad6b"
   },
   "source": [
    "The data augmentation is always important to an image recognition case.\n",
    "\n",
    "After all, more data, better performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "b342befe-1a6f-44bf-8dab-28033a729122",
    "_execution_state": "idle",
    "_uuid": "21d6192c87d92d497c797656474bccd9cefc5647"
   },
   "outputs": [],
   "source": [
    "idg = ImageDataGenerator(\n",
    "        rotation_range=5, \n",
    "        zoom_range = 0.1,\n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1)  \n",
    "\n",
    "\n",
    "idg.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "b453af8d-9736-43e3-b486-7a1cd7dd8909",
    "_execution_state": "idle",
    "_uuid": "cf36b3d029f95b553be02d612e097a9769ee8252",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Leon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "378/378 [==============================] - 157s 414ms/step - loss: 0.4482 - acc: 0.8599 - val_loss: 0.0634 - val_acc: 0.9812\n",
      "Epoch 2/30\n",
      "378/378 [==============================] - 156s 413ms/step - loss: 0.1051 - acc: 0.9684 - val_loss: 0.0615 - val_acc: 0.9824\n",
      "Epoch 3/30\n",
      "378/378 [==============================] - 156s 412ms/step - loss: 0.0774 - acc: 0.9767 - val_loss: 0.0730 - val_acc: 0.9802\n",
      "Epoch 4/30\n",
      "378/378 [==============================] - 156s 412ms/step - loss: 0.0662 - acc: 0.9798 - val_loss: 0.0591 - val_acc: 0.9833\n",
      "Epoch 5/30\n",
      "378/378 [==============================] - 156s 413ms/step - loss: 0.0572 - acc: 0.9830 - val_loss: 0.0369 - val_acc: 0.9883\n",
      "Epoch 6/30\n",
      "378/378 [==============================] - 155s 410ms/step - loss: 0.0509 - acc: 0.9851 - val_loss: 0.0353 - val_acc: 0.9902\n",
      "Epoch 7/30\n",
      "378/378 [==============================] - 155s 409ms/step - loss: 0.0485 - acc: 0.9852 - val_loss: 0.0274 - val_acc: 0.9924\n",
      "Epoch 8/30\n",
      "378/378 [==============================] - 155s 409ms/step - loss: 0.0437 - acc: 0.9863 - val_loss: 0.0367 - val_acc: 0.9898\n",
      "Epoch 9/30\n",
      "378/378 [==============================] - 155s 411ms/step - loss: 0.0396 - acc: 0.9878 - val_loss: 0.0365 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/30\n",
      "378/378 [==============================] - 156s 412ms/step - loss: 0.0293 - acc: 0.9910 - val_loss: 0.0314 - val_acc: 0.9912\n",
      "Epoch 11/30\n",
      "378/378 [==============================] - 156s 412ms/step - loss: 0.0301 - acc: 0.9917 - val_loss: 0.0269 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/30\n",
      "378/378 [==============================] - 155s 410ms/step - loss: 0.0221 - acc: 0.9931 - val_loss: 0.0214 - val_acc: 0.9948\n",
      "Epoch 13/30\n",
      "378/378 [==============================] - 155s 409ms/step - loss: 0.0209 - acc: 0.9938 - val_loss: 0.0227 - val_acc: 0.9936\n",
      "Epoch 14/30\n",
      "378/378 [==============================] - 155s 409ms/step - loss: 0.0190 - acc: 0.9942 - val_loss: 0.0237 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 15/30\n",
      "378/378 [==============================] - 154s 408ms/step - loss: 0.0179 - acc: 0.9944 - val_loss: 0.0227 - val_acc: 0.9943\n",
      "Epoch 16/30\n",
      "378/378 [==============================] - 154s 408ms/step - loss: 0.0176 - acc: 0.9944 - val_loss: 0.0217 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 17/30\n",
      "378/378 [==============================] - 154s 408ms/step - loss: 0.0163 - acc: 0.9954 - val_loss: 0.0193 - val_acc: 0.9945\n",
      "Epoch 18/30\n",
      "378/378 [==============================] - 155s 409ms/step - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0199 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 19/30\n",
      "378/378 [==============================] - 154s 408ms/step - loss: 0.0146 - acc: 0.9952 - val_loss: 0.0211 - val_acc: 0.9936\n",
      "Epoch 20/30\n",
      "378/378 [==============================] - 154s 409ms/step - loss: 0.0139 - acc: 0.9953 - val_loss: 0.0209 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 21/30\n",
      "378/378 [==============================] - 154s 408ms/step - loss: 0.0142 - acc: 0.9957 - val_loss: 0.0199 - val_acc: 0.9940\n",
      "Epoch 22/30\n",
      "378/378 [==============================] - 157s 416ms/step - loss: 0.0129 - acc: 0.9962 - val_loss: 0.0194 - val_acc: 0.9950\n",
      "Epoch 23/30\n",
      "378/378 [==============================] - 154s 409ms/step - loss: 0.0137 - acc: 0.9956 - val_loss: 0.0198 - val_acc: 0.9948\n",
      "Epoch 24/30\n",
      "378/378 [==============================] - 155s 410ms/step - loss: 0.0140 - acc: 0.9955 - val_loss: 0.0201 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 25/30\n",
      "378/378 [==============================] - 155s 410ms/step - loss: 0.0139 - acc: 0.9956 - val_loss: 0.0195 - val_acc: 0.9948\n",
      "Epoch 26/30\n",
      "378/378 [==============================] - 155s 409ms/step - loss: 0.0122 - acc: 0.9959 - val_loss: 0.0199 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 27/30\n",
      "378/378 [==============================] - 154s 409ms/step - loss: 0.0142 - acc: 0.9954 - val_loss: 0.0199 - val_acc: 0.9950\n",
      "Epoch 28/30\n",
      "378/378 [==============================] - 154s 408ms/step - loss: 0.0126 - acc: 0.9963 - val_loss: 0.0199 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 29/30\n",
      "378/378 [==============================] - 154s 408ms/step - loss: 0.0138 - acc: 0.9958 - val_loss: 0.0198 - val_acc: 0.9948\n",
      "Epoch 30/30\n",
      "378/378 [==============================] - 154s 408ms/step - loss: 0.0130 - acc: 0.9960 - val_loss: 0.0197 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1e-06.\n"
     ]
    }
   ],
   "source": [
    "result = model.fit_generator(idg.flow(X_train,y_train, batch_size=100),\n",
    "                              epochs = 30, validation_data = (X_val,y_val),\n",
    "                              verbose = 1, steps_per_epoch=X_train.shape[0] // 100\n",
    "                              , callbacks=[monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the history of 'loss' & accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.06510440878558993,\n",
       "  0.049494844839154256,\n",
       "  0.04574305995456165,\n",
       "  0.05876270662771449,\n",
       "  0.03141794066149963,\n",
       "  0.02396643123107164,\n",
       "  0.025283156824852562,\n",
       "  0.04446101080005368,\n",
       "  0.03488339862364921,\n",
       "  0.027083778694629603,\n",
       "  0.029354957732721232,\n",
       "  0.028029050982219077,\n",
       "  0.0226113167852981,\n",
       "  0.02442904334678869,\n",
       "  0.022666774908776416,\n",
       "  0.02623339320970921,\n",
       "  0.023264806750895723,\n",
       "  0.02185374188134336,\n",
       "  0.021316105462964124,\n",
       "  0.020281100387191622,\n",
       "  0.022671939799606446,\n",
       "  0.022205599537344477,\n",
       "  0.02293139969939754,\n",
       "  0.020016530729359754,\n",
       "  0.020774210970730997,\n",
       "  0.021946270846975886,\n",
       "  0.021328852136451002,\n",
       "  0.02187487220128657,\n",
       "  0.02061242317393494,\n",
       "  0.021241857470635124],\n",
       " 'val_acc': [0.9804761991614387,\n",
       "  0.9854762014888582,\n",
       "  0.9854761986505418,\n",
       "  0.9835714385623023,\n",
       "  0.9916666746139526,\n",
       "  0.992380956808726,\n",
       "  0.9919047667866662,\n",
       "  0.9885714394705636,\n",
       "  0.9890476252351489,\n",
       "  0.9919047682058244,\n",
       "  0.9919047682058244,\n",
       "  0.9914285796029227,\n",
       "  0.993571434702192,\n",
       "  0.9935714332830339,\n",
       "  0.993571434702192,\n",
       "  0.9916666731947944,\n",
       "  0.9928571496691022,\n",
       "  0.993809529713222,\n",
       "  0.993809529713222,\n",
       "  0.9942857197352818,\n",
       "  0.9940476247242519,\n",
       "  0.9923809582278842,\n",
       "  0.9940476247242519,\n",
       "  0.9945238147463117,\n",
       "  0.993809529713222,\n",
       "  0.9923809582278842,\n",
       "  0.9933333396911621,\n",
       "  0.993809529713222,\n",
       "  0.9933333396911621,\n",
       "  0.9930952446801322],\n",
       " 'loss': [0.43046853380898636,\n",
       "  0.10194466189880456,\n",
       "  0.07390667371964328,\n",
       "  0.059825208583211026,\n",
       "  0.05807309345312653,\n",
       "  0.05086949648379925,\n",
       "  0.0473762053749019,\n",
       "  0.04422700960942416,\n",
       "  0.04140526979882024,\n",
       "  0.029100646909447043,\n",
       "  0.027601236702009504,\n",
       "  0.025772015609108304,\n",
       "  0.022940667873376577,\n",
       "  0.02141028762095615,\n",
       "  0.01913983109188463,\n",
       "  0.02004191584123801,\n",
       "  0.01574053054081988,\n",
       "  0.01601745409144319,\n",
       "  0.01453672771123589,\n",
       "  0.014142086880277564,\n",
       "  0.013801628754008947,\n",
       "  0.014107694598986574,\n",
       "  0.013035088464175474,\n",
       "  0.012521178471967,\n",
       "  0.012028640752365516,\n",
       "  0.0122666469396598,\n",
       "  0.012212648270029585,\n",
       "  0.011588165651128822,\n",
       "  0.011260841283988807,\n",
       "  0.011629567642418407],\n",
       " 'acc': [0.8624338636756259,\n",
       "  0.9695238168277438,\n",
       "  0.977724878560929,\n",
       "  0.9813227617236041,\n",
       "  0.9827513332089419,\n",
       "  0.9842328139083095,\n",
       "  0.9862698513679403,\n",
       "  0.9866402215427823,\n",
       "  0.9880423375538417,\n",
       "  0.9906084736188253,\n",
       "  0.992010589156832,\n",
       "  0.9922751393267717,\n",
       "  0.9925396893390273,\n",
       "  0.9936243445469589,\n",
       "  0.9943915392671313,\n",
       "  0.993941804246297,\n",
       "  0.9951587347757249,\n",
       "  0.9951587347757249,\n",
       "  0.9957142898014614,\n",
       "  0.9955291046351983,\n",
       "  0.9958730198088146,\n",
       "  0.9956613797990103,\n",
       "  0.9959788398137168,\n",
       "  0.9962698448271978,\n",
       "  0.9965079398382277,\n",
       "  0.9962433898259723,\n",
       "  0.9959523848124913,\n",
       "  0.9961640248222957,\n",
       "  0.9966137598431299,\n",
       "  0.9962962998284234],\n",
       " 'lr': [0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.0005,\n",
       "  0.0005,\n",
       "  0.0005,\n",
       "  0.00025,\n",
       "  0.00025,\n",
       "  0.00025,\n",
       "  0.00025,\n",
       "  0.000125,\n",
       "  0.000125,\n",
       "  0.000125,\n",
       "  0.000125,\n",
       "  0.000125,\n",
       "  0.000125,\n",
       "  0.000125,\n",
       "  6.25e-05,\n",
       "  6.25e-05,\n",
       "  6.25e-05,\n",
       "  6.25e-05,\n",
       "  3.125e-05,\n",
       "  3.125e-05,\n",
       "  3.125e-05]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the diagram for viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result.history['acc'],label='Train accuracy')\n",
    "plt.plot(result.history['val_acc'],label='Val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both train (99.6%) and validation (99.3%) accuracy is high (or meet the expectation) and no significant gap between train and validation sets.\n",
    "\n",
    "We can consider that the model has good performance without under-fitting and over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and perform the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "05ff3b9f-c3bb-4cec-a8c2-2c128e8f15b3",
    "_execution_state": "idle",
    "_uuid": "7f17e7bf0a54a01a52fef2d554780f6bc6580dc6"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test)\n",
    "pred = np.argmax(pred,axis = 1)\n",
    "sub['Label'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"cnn_adam.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy is **99.64%**!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
