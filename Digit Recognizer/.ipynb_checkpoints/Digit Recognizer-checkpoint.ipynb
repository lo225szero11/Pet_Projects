{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d4c08f48-fe23-4ddb-ac46-d97f05397514",
    "_uuid": "f2156d1dd26a1243e18512002e10872c5bd7271e"
   },
   "source": [
    "# Digit Recognizer\n",
    "Arthur: Leon Lai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network (CNN) is very powerful for image recognition!\n",
    "\n",
    "Let's get started! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "f67b9393-8ea1-4e23-b856-2ce149cfe421",
    "_execution_state": "idle",
    "_uuid": "72334cb006d02a4bcfc2a2fe622524eba824c6f8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6d2fb3e6-ab71-4974-b5a2-4af1ebdb99f4",
    "_execution_state": "idle",
    "_uuid": "86061d98eccaa02efe0dab0fa3884e71fcf4c310"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "5e51d00e-62fd-4141-bf73-50ac4f2da7d0",
    "_execution_state": "idle",
    "_uuid": "84bbd5ab8d7895bd430d5ecfe2f7ddf77baa7b74"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "\n",
       "[3 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data description, each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. \n",
    "\n",
    "The feature 'label' is the number of each image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the quantity of each number in the train set first!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "86570a36-5c20-460a-9dfd-2070548532a7",
    "_execution_state": "idle",
    "_uuid": "1213b979d5ed3e0d13824d17d694c79d2ece92fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train['label']\n",
    "X_train = train.drop('label',axis = 1) \n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5aea4062-1790-4987-b739-c4bebd79030f",
    "_uuid": "b7b1b1d36243c885e57374c8b60c5a7e10abe922"
   },
   "source": [
    "It seems that there are similar counts for 0 ~ 9 digits. Good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5b7d4b66-a140-4fcc-a889-bcef007c880a",
    "_uuid": "5d77934302869925c19128c77e247b3c8ca84d71"
   },
   "source": [
    "**We also need to check if there are missing values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "ececaa00-2ae3-4d13-b631-438df085b030",
    "_execution_state": "idle",
    "_uuid": "cdf27c27e2a5b15e6d7bfc70de7a18c08f3feb7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "92572e80-8543-4e72-8767-5c9be8381b04",
    "_execution_state": "idle",
    "_uuid": "a0089bb7ec9aec76373db475399aea24699ae989"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09d04cae-4245-4659-85dd-ef48531da295",
    "_uuid": "c0bee59691c2df0b275c78e38e7f9907d02ac038"
   },
   "source": [
    "No missing data! We can go ahead!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6812040d-80ad-43d2-a571-275f4f20067b",
    "_uuid": "2954681f25f0dcbe986e6914396cdbce61db591f"
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "159d5854-437a-4d0f-bc1e-fc3f7e43d178",
    "_uuid": "0ecf4b52510ab7957d0d4eb646c0aa1ba5986273"
   },
   "source": [
    "Perform the normalization for images to make all the data values in the range of 0 ~ 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "cdc4340b-6e24-4e12-be99-ac806098ff17",
    "_execution_state": "idle",
    "_uuid": "b5d4f8fcf2a967e2c7d57daedf95aa8c5ab7f8cb"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7413df94-bcb9-4f75-b174-c127d4445766",
    "_uuid": "a66741bf1ac597094f3a3166877008feef27c519"
   },
   "source": [
    "## Reshape the data\n",
    "\n",
    "Just reshape the data as image input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "34b6a5f7-8fd2-4387-8ef4-c9dc19584fed",
    "_execution_state": "idle",
    "_uuid": "f0a6ad80dab8e0f2c2e46165ccd9cd82dd162bc3"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use **matplotlib.pyplot.imshow()** to view the images! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(X_train[0,:,:,0]); #change the first dimension (sample index) for viewing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bdb422e2-bdec-444f-97a5-283a1e54bf2c",
    "_uuid": "39b7a31e843bac6b705461bcce89da216b91799e"
   },
   "source": [
    "## Encode the label\n",
    "\n",
    "It's the multi-classfication case. The target feature 'label' will be transformed into one-hot encoding vector.\n",
    "\n",
    "For example, 1 -> [0,1,0,0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "4b7f3e78-44dc-4561-b1f0-9429ee024cf4",
    "_execution_state": "idle",
    "_uuid": "cabefd1478d5c1bdfe57fd6a34395340916a854c"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "32152fc3-a570-4d64-8a7d-6c689a4acd33",
    "_uuid": "d8abbbf31483b94e1b29d07c4c8253d1311648a7"
   },
   "source": [
    "## Split train set for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "dcd25ebb-d845-4d32-9867-082e352b1396",
    "_execution_state": "idle",
    "_uuid": "b779ac76d8317647db92d5a88b4098d212d72884"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d5265777-aeb3-449d-b171-d88cad74c0a4",
    "_uuid": "5fa18b37a9acd9e098bac1d12264b0dd4310fdd3"
   },
   "source": [
    "## Build the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we build is structured like a small VGG (one of classic CNN models).\n",
    "\n",
    "Do the batch normalization to speed up the optimization.\n",
    "\n",
    "Use dropout to reduce the over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "1e0f3f88-2ad7-459e-8e02-aecc5f3511ae",
    "_execution_state": "idle",
    "_uuid": "f7991ef6871a26f9fa57acdcd460a69bab53e804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Leon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Leon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                 input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Adam as optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "a4c55409-6a65-400a-b5e8-a1dc535429c0",
    "_execution_state": "idle",
    "_uuid": "420c704367b397b8255fefe9d882b35ac8929b95"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "0bd89b79-1a74-40da-af9a-7a76a8b96ff2",
    "_execution_state": "idle",
    "_uuid": "b4c0288622227a3cd05479aa765e324dbb852f34"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer= optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also use a monitor to control the learning rate if the accuracy doesn't decline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "b5987a18-6bbe-42a2-9d31-333ebc4f7af1",
    "_execution_state": "idle",
    "_uuid": "c4a5b4e462ec5362c47eef4fcc7956fd4e203307"
   },
   "outputs": [],
   "source": [
    "monitor = ReduceLROnPlateau(monitor='val_acc', \n",
    "                            patience=2, \n",
    "                            verbose=1, \n",
    "                            factor=0.5, \n",
    "                            min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "241a0f4f-13f5-4b13-be1e-4e3e4a714c06",
    "_uuid": "f24df64b223e0177c94025b6767ab19b722c5386"
   },
   "source": [
    "## Data augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e2d41e30-0724-40fb-a901-750e514ba9f9",
    "_uuid": "9e498b91419439f0fa791e595f202d9a0d56ad6b"
   },
   "source": [
    "The data augmentation is always important to an image recognition case.\n",
    "\n",
    "After all, more data, better performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "b342befe-1a6f-44bf-8dab-28033a729122",
    "_execution_state": "idle",
    "_uuid": "21d6192c87d92d497c797656474bccd9cefc5647"
   },
   "outputs": [],
   "source": [
    "idg = ImageDataGenerator(\n",
    "        rotation_range=5, \n",
    "        zoom_range = 0.1,\n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1)  \n",
    "\n",
    "\n",
    "idg.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "b453af8d-9736-43e3-b486-7a1cd7dd8909",
    "_execution_state": "idle",
    "_uuid": "cf36b3d029f95b553be02d612e097a9769ee8252",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Leon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "378/378 [==============================] - 156s 413ms/step - loss: 0.4515 - acc: 0.8570 - val_loss: 0.1759 - val_acc: 0.9510\n",
      "Epoch 2/30\n",
      "378/378 [==============================] - 154s 409ms/step - loss: 0.1047 - acc: 0.9681 - val_loss: 0.0550 - val_acc: 0.9843\n",
      "Epoch 3/30\n",
      "378/378 [==============================] - 156s 414ms/step - loss: 0.0773 - acc: 0.9766 - val_loss: 0.0448 - val_acc: 0.9869\n",
      "Epoch 4/30\n",
      "378/378 [==============================] - 156s 413ms/step - loss: 0.0657 - acc: 0.9803 - val_loss: 0.0523 - val_acc: 0.9857\n",
      "Epoch 5/30\n",
      "378/378 [==============================] - 157s 416ms/step - loss: 0.0557 - acc: 0.9830 - val_loss: 0.0367 - val_acc: 0.9883\n",
      "Epoch 6/30\n",
      "378/378 [==============================] - 155s 409ms/step - loss: 0.0500 - acc: 0.9854 - val_loss: 0.0482 - val_acc: 0.9857\n",
      "Epoch 7/30\n",
      "378/378 [==============================] - 160s 424ms/step - loss: 0.0495 - acc: 0.9850 - val_loss: 0.0350 - val_acc: 0.9890\n",
      "Epoch 8/30\n",
      "378/378 [==============================] - 157s 415ms/step - loss: 0.0419 - acc: 0.9871 - val_loss: 0.0260 - val_acc: 0.9917\n",
      "Epoch 9/30\n",
      "378/378 [==============================] - 154s 408ms/step - loss: 0.0383 - acc: 0.9883 - val_loss: 0.0324 - val_acc: 0.9917\n",
      "Epoch 10/30\n",
      "378/378 [==============================] - 154s 407ms/step - loss: 0.0375 - acc: 0.9886 - val_loss: 0.0367 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/30\n",
      "378/378 [==============================] - 155s 411ms/step - loss: 0.0274 - acc: 0.9911 - val_loss: 0.0212 - val_acc: 0.9938\n",
      "Epoch 12/30\n",
      "378/378 [==============================] - 156s 412ms/step - loss: 0.0248 - acc: 0.9925 - val_loss: 0.0279 - val_acc: 0.9926\n",
      "Epoch 13/30\n",
      "378/378 [==============================] - 154s 409ms/step - loss: 0.0231 - acc: 0.9927 - val_loss: 0.0276 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 14/30\n",
      "378/378 [==============================] - 154s 407ms/step - loss: 0.0210 - acc: 0.9934 - val_loss: 0.0216 - val_acc: 0.9933\n",
      "Epoch 15/30\n",
      "378/378 [==============================] - 155s 411ms/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.0228 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/30\n",
      "378/378 [==============================] - 154s 407ms/step - loss: 0.0181 - acc: 0.9949 - val_loss: 0.0235 - val_acc: 0.9938\n",
      "Epoch 17/30\n",
      "378/378 [==============================] - 155s 409ms/step - loss: 0.0165 - acc: 0.9947 - val_loss: 0.0242 - val_acc: 0.9940\n",
      "Epoch 18/30\n",
      "378/378 [==============================] - 155s 411ms/step - loss: 0.0155 - acc: 0.9951 - val_loss: 0.0222 - val_acc: 0.9940\n",
      "Epoch 19/30\n",
      "378/378 [==============================] - 156s 412ms/step - loss: 0.0139 - acc: 0.9958 - val_loss: 0.0218 - val_acc: 0.9943\n",
      "Epoch 20/30\n",
      "378/378 [==============================] - 154s 409ms/step - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0206 - val_acc: 0.9940\n",
      "Epoch 21/30\n",
      "378/378 [==============================] - 155s 411ms/step - loss: 0.0148 - acc: 0.9954 - val_loss: 0.0220 - val_acc: 0.9948\n",
      "Epoch 22/30\n",
      "378/378 [==============================] - 155s 411ms/step - loss: 0.0146 - acc: 0.9955 - val_loss: 0.0213 - val_acc: 0.9938\n",
      "Epoch 23/30\n",
      "378/378 [==============================] - 156s 413ms/step - loss: 0.0139 - acc: 0.9956 - val_loss: 0.0206 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 24/30\n",
      "378/378 [==============================] - 156s 412ms/step - loss: 0.0116 - acc: 0.9964 - val_loss: 0.0219 - val_acc: 0.9945\n",
      "Epoch 25/30\n",
      "378/378 [==============================] - 155s 410ms/step - loss: 0.0114 - acc: 0.9964 - val_loss: 0.0211 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 26/30\n",
      "378/378 [==============================] - 155s 411ms/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0204 - val_acc: 0.9940\n",
      "Epoch 27/30\n",
      "378/378 [==============================] - 156s 413ms/step - loss: 0.0112 - acc: 0.9965 - val_loss: 0.0205 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 28/30\n",
      "378/378 [==============================] - 154s 408ms/step - loss: 0.0104 - acc: 0.9963 - val_loss: 0.0201 - val_acc: 0.9948\n",
      "Epoch 29/30\n",
      "378/378 [==============================] - 155s 411ms/step - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0206 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 30/30\n",
      "378/378 [==============================] - 156s 411ms/step - loss: 0.0113 - acc: 0.9963 - val_loss: 0.0201 - val_acc: 0.9943\n"
     ]
    }
   ],
   "source": [
    "result = model.fit_generator(idg.flow(X_train,y_train, batch_size=100),\n",
    "                              epochs = 30, validation_data = (X_val,y_val),\n",
    "                              verbose = 1, steps_per_epoch=X_train.shape[0] // 100\n",
    "                              , callbacks=[monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the history of 'loss' & accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.1759498342871666,\n",
       "  0.055044139325175254,\n",
       "  0.044834507088775614,\n",
       "  0.05234838968109606,\n",
       "  0.03670057819025325,\n",
       "  0.04816325763905687,\n",
       "  0.03498140300784837,\n",
       "  0.025984264463962365,\n",
       "  0.032376169881206895,\n",
       "  0.03665935594610693,\n",
       "  0.021161819124245085,\n",
       "  0.027897851172037053,\n",
       "  0.027639176269682746,\n",
       "  0.02161487273059763,\n",
       "  0.022821857648783146,\n",
       "  0.023539539116557404,\n",
       "  0.02417232263126477,\n",
       "  0.022213892569111306,\n",
       "  0.021848560578118417,\n",
       "  0.020571681146975607,\n",
       "  0.021955960664031625,\n",
       "  0.021301348412851525,\n",
       "  0.02062884526371601,\n",
       "  0.02190359001910803,\n",
       "  0.021074803651052725,\n",
       "  0.020373857754315224,\n",
       "  0.020529324548641897,\n",
       "  0.020112614915411713,\n",
       "  0.020572002842051178,\n",
       "  0.020136440960976915],\n",
       " 'val_acc': [0.9509523865722475,\n",
       "  0.9842857207570758,\n",
       "  0.9869047701358795,\n",
       "  0.9857142950807299,\n",
       "  0.9883333430403755,\n",
       "  0.9857142936615717,\n",
       "  0.9890476280734652,\n",
       "  0.9916666746139526,\n",
       "  0.9916666717756362,\n",
       "  0.9914285796029227,\n",
       "  0.993809529713222,\n",
       "  0.9926190546580723,\n",
       "  0.9926190546580723,\n",
       "  0.9933333382720039,\n",
       "  0.9930952446801322,\n",
       "  0.993809529713222,\n",
       "  0.9940476233050937,\n",
       "  0.9940476247242519,\n",
       "  0.9942857197352818,\n",
       "  0.9940476247242519,\n",
       "  0.9947619097573417,\n",
       "  0.993809529713222,\n",
       "  0.9945238147463117,\n",
       "  0.9945238133271536,\n",
       "  0.9942857183161236,\n",
       "  0.9940476233050937,\n",
       "  0.9940476233050937,\n",
       "  0.9947619097573417,\n",
       "  0.9947619097573417,\n",
       "  0.9942857183161236],\n",
       " 'loss': [0.45154351909600554,\n",
       "  0.10471223145674066,\n",
       "  0.07725519420229214,\n",
       "  0.06568958435118907,\n",
       "  0.05573780877483644,\n",
       "  0.04995888005572534,\n",
       "  0.04952232613907043,\n",
       "  0.04192603231720607,\n",
       "  0.03829547027883578,\n",
       "  0.03747622586944431,\n",
       "  0.027367085312593548,\n",
       "  0.024818688600106047,\n",
       "  0.023081727095087497,\n",
       "  0.021042160549701226,\n",
       "  0.019327215961494455,\n",
       "  0.01809908241757608,\n",
       "  0.016466601979262786,\n",
       "  0.015528335175341459,\n",
       "  0.013877786693878338,\n",
       "  0.01360940996385931,\n",
       "  0.014756068012541007,\n",
       "  0.014644126256989597,\n",
       "  0.01393038708046473,\n",
       "  0.011636362320459547,\n",
       "  0.011363403467859065,\n",
       "  0.012406065704006266,\n",
       "  0.011166471516988831,\n",
       "  0.010444625919965336,\n",
       "  0.010322827013272905,\n",
       "  0.011318516966341082],\n",
       " 'acc': [0.8570105834376245,\n",
       "  0.9680687911296016,\n",
       "  0.9765873111429668,\n",
       "  0.980343926047522,\n",
       "  0.9829894291660773,\n",
       "  0.9854497464876326,\n",
       "  0.9849735552040988,\n",
       "  0.9871164120378948,\n",
       "  0.9882539780366988,\n",
       "  0.9885714371052999,\n",
       "  0.9910582086396595,\n",
       "  0.9925132341801174,\n",
       "  0.992698419661749,\n",
       "  0.993359794219335,\n",
       "  0.9940211692499736,\n",
       "  0.9949470941351835,\n",
       "  0.9946560897524395,\n",
       "  0.9951058247732738,\n",
       "  0.9958201098063636,\n",
       "  0.9957671996462282,\n",
       "  0.9954497397892059,\n",
       "  0.9955291046351983,\n",
       "  0.9956349246401005,\n",
       "  0.9964285748345512,\n",
       "  0.9964021198333256,\n",
       "  0.9962962998284234,\n",
       "  0.9965079398382277,\n",
       "  0.9963227548296489,\n",
       "  0.9966931248468066,\n",
       "  0.9962962998284234],\n",
       " 'lr': [0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.0005,\n",
       "  0.0005,\n",
       "  0.0005,\n",
       "  0.00025,\n",
       "  0.00025,\n",
       "  0.000125,\n",
       "  0.000125,\n",
       "  0.000125,\n",
       "  0.000125,\n",
       "  0.000125,\n",
       "  0.000125,\n",
       "  0.000125,\n",
       "  0.000125,\n",
       "  6.25e-05,\n",
       "  6.25e-05,\n",
       "  3.125e-05,\n",
       "  3.125e-05,\n",
       "  1.5625e-05,\n",
       "  1.5625e-05,\n",
       "  7.8125e-06]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the diagram for viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result.history['acc'],label='Train accuracy')\n",
    "plt.plot(result.history['val_acc'],label='Val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both train (99.6%) and validation (99.4%) accuracy is high (or meet the expectation) and no significant gap between train and validation sets.\n",
    "\n",
    "We can consider that the model has good performance without under-fitting and over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and perform the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "05ff3b9f-c3bb-4cec-a8c2-2c128e8f15b3",
    "_execution_state": "idle",
    "_uuid": "7f17e7bf0a54a01a52fef2d554780f6bc6580dc6"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test)\n",
    "pred = np.argmax(pred,axis = 1)\n",
    "sub['Label'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"cnn_adam.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy is **99.64%**!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
